<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>CTCL</title>
    <meta name="author" content="Jinjing Zhu">
    <meta name="description" content="Project page of CNN-Transformer Collaborative Learning paper, ICCV 2023">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="iccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style=“text-align: center;”>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                A Good Student is Cooperative and Reliable: CNN-Transformer Collaborative Learning for Semantic Segmentation<br /> 
<!--                 <small>
                    
                </small> -->
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
		    
                    <li>
			<img src="./image/81.jpg" height="80px"><br>
                        Jinjing Zhu
                      </a>
                      <br /> AI Thrust, HKUST(GZ)
                      <br /> &nbsp &nbsp
                    </li>

		    <li>
			    <img src="./image/yunhao.jpg" height="80px"><br>
                        <a href="" >
                           Yunhao Luo
                        </a>
                        <br /> Brown University
                      <br /> &nbsp &nbsp

                    </li>
			
                    <li>
			<img src="./image/zheng1.png" height="80px"><br>
                        <a href="https://zhengxujosh.github.io/" >
                         Xu Zheng
                        </a>
                        
                        <br /> AI Thrust, HKUST(GZ)
                        <br /> &nbsp &nbsp

                    </li>

                  
                    <li>
			    <img src="./image/linwang.jpg" height="80px"><br>
                        <a href="https://addisonwang2013.github.io/vlislab/linwang.html">
                           Addison Lin Wang
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			    <br/> Dept. of CSE, HKUST 
                    </li>
                </ul>
            </div>
        </div>

	
        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			                <a href="">
                            <img src="./image/arxiv.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>

                            <img src="./image/youtube_icon.jpg" height="100px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https:">
                            <img src="./image/github_icon.jpg" height="100px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>

                        <!-- <li>
                            
                            <img src="./image/colab_icon.jpg" height="100px"><br>
                                <h4><strong>Colab</strong></h4>
                            </a>
                        </li> -->
 

                        <li>
                            <!-- <a href="https://github.com/haoai-1997/haoai-1997.github.io/blob/main/HRDFuse/CVPR2023_HRDFuse_supp.pdf"> -->
                            <img src="./image/slide_icon.jpg" height="100px"><br>
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>                     
                        <li>
                            <a href="https://vlislab22.github.io/vlislab/">
                            <img src="./image/lab_logo.png" height="100px"><br>
                                <h4><strong>Vlislab</strong></h4>
                            </a>
                        </li>                       
                      
                    </ul>
                </div>
        </div>

	    
        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
	               In this paper, we strive to answer the question ‘how to collaboratively learn convolutional neural network (CNN)-based and vision transformer (ViT)-based models by selecting and exchanging the reliable knowledge between them for semantic segmentation?’ Accordingly, we propose an online knowledge distillation (KD) framework that can simultaneously learn compact yet effective CNN-based and ViT-based models with two key technical breakthroughs to take full advantage of CNNs and ViT while compensating their limitations. Firstly, we propose heterogeneous feature distillation (HFD) to improve students’ consistency in low-layer feature space by mimicking heterogeneous features between CNNs and ViT. Secondly, to facilitate the two students to learn reliable knowledge from each other, we propose bidirectional selective distillation (BSD) that can dynamically transfer selective knowledge. This is achieved by 1) region-wise BSD determining the directions of knowledge transferred between the corresponding regions in the feature space and 2) pixel-wise BSD discerning which of the prediction knowledge to be transferred in the logit space. Extensive experiments on three benchmark datasets demonstrate that our proposed framework outperforms the state-of-the-art online distillation methods by a large margin, and shows its efficacy in learning collaboratively between ViT-based and CNN-based models.
                    <br>
                    <br>
                </p>
            </div>
        </div>
	    
        <!-- ##### Results #####-->

     <div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Experimental Results
            </h3>
            <img src="./image/result.jpg" class="img-responsive" alt="vis_res"  class="center" >
      </div>           
     
    </div>

   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
@inproceedings{Zheng2023DATR,
  title={A Good Student is Cooperative and Reliable: CNN-Transformer Collaborative Learning for Semantic Segmentation},
  author={Jinjing Zhu, Yunhao Luo, Xu Zheng, Lin Wang},
  booktitle = {IEEE International Conference on Computer Vision (ICCV)},
  year={2023}
}
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
